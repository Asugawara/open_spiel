{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from open_spiel.python import policy\n",
    "from open_spiel.python import rl_environment\n",
    "from open_spiel.python.algorithms import exploitability\n",
    "from open_spiel.python.algorithms import policy_gradient\n",
    "import policy_gradient as pt_policy_gradient\n",
    "\n",
    "\n",
    "\n",
    "class PolicyGradientPolicies(policy.Policy):\n",
    "  \"\"\"Joint policy to be evaluated.\"\"\"\n",
    "\n",
    "  def __init__(self, env, nfsp_policies):\n",
    "    game = env.game\n",
    "    player_ids = [0, 1]\n",
    "    super(PolicyGradientPolicies, self).__init__(game, player_ids)\n",
    "    self._policies = nfsp_policies\n",
    "    self._obs = {\"info_state\": [None, None], \"legal_actions\": [None, None]}\n",
    "\n",
    "  def action_probabilities(self, state, player_id=None):\n",
    "    cur_player = state.current_player()\n",
    "    legal_actions = state.legal_actions(cur_player)\n",
    "\n",
    "    self._obs[\"current_player\"] = cur_player\n",
    "    self._obs[\"info_state\"][cur_player] = (\n",
    "        state.information_state_tensor(cur_player))\n",
    "    self._obs[\"legal_actions\"][cur_player] = legal_actions\n",
    "\n",
    "    info_state = rl_environment.TimeStep(\n",
    "        observations=self._obs, rewards=None, discounts=None, step_type=None)\n",
    "\n",
    "    p = self._policies[cur_player].step(info_state, is_evaluation=True).probs\n",
    "    prob_dict = {action: p[action] for action in legal_actions}\n",
    "    return prob_dict\n",
    "\n",
    "\n",
    "def test_tf(game, num_episodes, eval_every, loss_str):\n",
    "  \"\"\"\n",
    "  loss_str:[\"a2c\", \"rpg\", \"qpg\", \"rm\"]\n",
    "  \"\"\"\n",
    "  num_players = 2\n",
    "\n",
    "  env_configs = {\"players\": num_players}\n",
    "  env = rl_environment.Environment(game, **env_configs)\n",
    "  info_state_size = env.observation_spec()[\"info_state\"][0]\n",
    "  num_actions = env.action_spec()[\"num_actions\"]\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    # pylint: disable=g-complex-comprehension\n",
    "    agents = [\n",
    "        policy_gradient.PolicyGradient(\n",
    "            sess,\n",
    "            idx,\n",
    "            info_state_size,\n",
    "            num_actions,\n",
    "            loss_str=loss_str,\n",
    "            hidden_layers_sizes=(128,)) for idx in range(num_players)\n",
    "    ]\n",
    "    expl_policies_avg = PolicyGradientPolicies(env, agents)\n",
    "    result = []\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for ep in range(num_episodes):\n",
    "\n",
    "      if (ep + 1) % eval_every == 0:\n",
    "        losses = [agent.loss for agent in agents]\n",
    "        expl = exploitability.exploitability(env.game, expl_policies_avg)\n",
    "        result.append(expl)\n",
    "        print(ep+1, expl)\n",
    "\n",
    "      time_step = env.reset()\n",
    "      while not time_step.last():\n",
    "        player_id = time_step.observations[\"current_player\"]\n",
    "        agent_output = agents[player_id].step(time_step)\n",
    "        action_list = [agent_output.action]\n",
    "        time_step = env.step(action_list)\n",
    "\n",
    "      # Episode is over, step all agents with final info state.\n",
    "      for agent in agents:\n",
    "        agent.step(time_step)\n",
    "  return result\n",
    "\n",
    "        \n",
    "def test_pt(game, num_episodes, eval_every, loss_str):\n",
    "  \"\"\"\n",
    "  loss_str:[\"a2c\", \"rpg\", \"qpg\", \"rm\"]\n",
    "  \"\"\"\n",
    "  num_players = 2\n",
    "\n",
    "  env_configs = {\"players\": num_players}\n",
    "  env = rl_environment.Environment(game, **env_configs)\n",
    "  info_state_size = env.observation_spec()[\"info_state\"][0]\n",
    "  num_actions = env.action_spec()[\"num_actions\"]\n",
    "\n",
    "  # pylint: disable=g-complex-comprehension\n",
    "  agents = [\n",
    "      pt_policy_gradient.PolicyGradient(\n",
    "          idx,\n",
    "          info_state_size,\n",
    "          num_actions,\n",
    "          loss_str=loss_str,\n",
    "          hidden_layers_sizes=(128,)) for idx in range(num_players)\n",
    "  ]\n",
    "  expl_policies_avg = PolicyGradientPolicies(env, agents)\n",
    "  result = []\n",
    "  for ep in range(num_episodes):\n",
    "  \n",
    "    if (ep + 1) % eval_every == 0:\n",
    "      losses = [agent.loss for agent in agents]\n",
    "      expl = exploitability.exploitability(env.game, expl_policies_avg)\n",
    "      result.append(expl)\n",
    "      print(ep+1, expl)\n",
    "  \n",
    "    time_step = env.reset()\n",
    "    while not time_step.last():\n",
    "      player_id = time_step.observations[\"current_player\"]\n",
    "      agent_output = agents[player_id].step(time_step)\n",
    "      action_list = [agent_output.action]\n",
    "      time_step = env.step(action_list)\n",
    "  \n",
    "    # Episode is over, step all agents with final info state.\n",
    "    for agent in agents:\n",
    "      agent.step(time_step)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = int(1e5)\n",
    "EVAL_EVERY = int(1e4)\n",
    "LOSS_STR = 'a2c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.37900984807950605\n",
      "20000 0.32177749715166226\n",
      "30000 0.2988562104484438\n",
      "40000 0.29518197830443826\n",
      "50000 0.2915205565020096\n",
      "60000 0.2893561715284406\n",
      "70000 0.28679159436437335\n",
      "80000 0.2845466054763692\n",
      "90000 0.281548425862029\n",
      "100000 0.2785872204966148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37900984807950605,\n",
       " 0.32177749715166226,\n",
       " 0.2988562104484438,\n",
       " 0.29518197830443826,\n",
       " 0.2915205565020096,\n",
       " 0.2893561715284406,\n",
       " 0.28679159436437335,\n",
       " 0.2845466054763692,\n",
       " 0.281548425862029,\n",
       " 0.2785872204966148]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_res = test_tf('kuhn_poker', NUM_EPISODES, EVAL_EVERY, LOSS_STR)\n",
    "tf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.3620111648885066\n",
      "20000 0.31271177510954773\n",
      "30000 0.29973228050132517\n",
      "40000 0.29117547732525173\n",
      "50000 0.2869790826510561\n",
      "60000 0.2802378814424329\n",
      "70000 0.27519049690420605\n",
      "80000 0.2703495365791758\n",
      "90000 0.26785184518091587\n",
      "100000 0.26297236263585877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3620111648885066,\n",
       " 0.31271177510954773,\n",
       " 0.29973228050132517,\n",
       " 0.29117547732525173,\n",
       " 0.2869790826510561,\n",
       " 0.2802378814424329,\n",
       " 0.27519049690420605,\n",
       " 0.2703495365791758,\n",
       " 0.26785184518091587,\n",
       " 0.26297236263585877]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_res = test_pt('kuhn_poker', NUM_EPISODES, EVAL_EVERY, LOSS_STR)\n",
    "pt_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = int(1e5)\n",
    "EVAL_EVERY = int(1e4)\n",
    "LOSS_STR = 'a2c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.2392726266077894\n",
      "20000 2.239777544707624\n",
      "30000 2.2255411968226078\n",
      "40000 2.1410972362134126\n",
      "50000 2.115922933413102\n",
      "60000 2.05420737023231\n",
      "70000 1.98743257776856\n",
      "80000 2.024815840747584\n",
      "90000 1.911366473818718\n",
      "100000 1.8708556764754363\n",
      "[2.2392726266077894, 2.239777544707624, 2.2255411968226078, 2.1410972362134126, 2.115922933413102, 2.05420737023231, 1.98743257776856, 2.024815840747584, 1.911366473818718, 1.8708556764754363]\n",
      "10000 2.595945624369934\n",
      "20000 2.3978561096544\n",
      "30000 2.2754552938515595\n",
      "40000 2.292387165236848\n",
      "50000 2.161305849638241\n",
      "60000 2.1529491120985345\n",
      "70000 2.066636061867233\n",
      "80000 2.05650548975179\n",
      "90000 2.0750003303561826\n",
      "100000 2.029161603889028\n",
      "[2.595945624369934, 2.3978561096544, 2.2754552938515595, 2.292387165236848, 2.161305849638241, 2.1529491120985345, 2.066636061867233, 2.05650548975179, 2.0750003303561826, 2.029161603889028]\n",
      "10000 2.369499491805596\n",
      "20000 2.1855354212742903\n",
      "30000 2.2028650242181054\n",
      "40000 2.1622182114165285\n",
      "50000 2.165994703512826\n",
      "60000 2.0638300353853447\n",
      "70000 1.9897424780808475\n",
      "80000 1.9876378261285481\n",
      "90000 1.936542564309626\n",
      "100000 1.820292484546954\n",
      "[2.369499491805596, 2.1855354212742903, 2.2028650242181054, 2.1622182114165285, 2.165994703512826, 2.0638300353853447, 1.9897424780808475, 1.9876378261285481, 1.936542564309626, 1.820292484546954]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    tf_res = test_tf('leduc_poker', NUM_EPISODES, EVAL_EVERY, LOSS_STR)\n",
    "    print(tf_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.2749961873716575\n",
      "20000 2.2666778677428434\n",
      "30000 2.165287145100697\n",
      "40000 2.079457954314968\n",
      "50000 2.0918588635337105\n",
      "60000 2.044400192524746\n",
      "70000 2.027876559334195\n",
      "80000 2.030867540135744\n",
      "90000 1.9833670682156674\n",
      "100000 1.9716290231472917\n",
      "[2.2749961873716575, 2.2666778677428434, 2.165287145100697, 2.079457954314968, 2.0918588635337105, 2.044400192524746, 2.027876559334195, 2.030867540135744, 1.9833670682156674, 1.9716290231472917]\n",
      "10000 2.2145492130950784\n",
      "20000 2.1373351079906295\n",
      "30000 2.1402202167504245\n",
      "40000 2.1780810582849908\n",
      "50000 2.0549493290473118\n",
      "60000 2.0663108221192696\n",
      "70000 2.007294744892595\n",
      "80000 1.913486012680631\n",
      "90000 1.9452607731626874\n",
      "100000 1.8692626557938719\n",
      "[2.2145492130950784, 2.1373351079906295, 2.1402202167504245, 2.1780810582849908, 2.0549493290473118, 2.0663108221192696, 2.007294744892595, 1.913486012680631, 1.9452607731626874, 1.8692626557938719]\n",
      "10000 2.5407027568810427\n",
      "20000 2.4192188835878694\n",
      "30000 2.3870904835765687\n",
      "40000 2.3705128244737397\n",
      "50000 2.37103139407428\n",
      "60000 2.3825592925303614\n",
      "70000 2.2912773913589364\n",
      "80000 2.14614239071165\n",
      "90000 2.1098058047302484\n",
      "100000 2.122468933162436\n",
      "[2.5407027568810427, 2.4192188835878694, 2.3870904835765687, 2.3705128244737397, 2.37103139407428, 2.3825592925303614, 2.2912773913589364, 2.14614239071165, 2.1098058047302484, 2.122468933162436]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    pt_res = test_pt('leduc_poker', NUM_EPISODES, EVAL_EVERY, LOSS_STR)\n",
    "    print(pt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
